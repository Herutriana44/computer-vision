{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import label as lab\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import binary_erosion\n",
    "from skimage.measure import regionprops_table\n",
    "from skimage.measure import moments_hu\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import img_as_ubyte\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import json\n",
    "from hsv import HsvExtractor\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import json\n",
    "from hsv import HsvExtractor\n",
    "import os\n",
    "\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "    \n",
    "    # Ubah gambar menjadi grayscale\n",
    "    gray_image = rgb2gray(image)\n",
    "    gray_image = img_as_ubyte(gray_image)\n",
    "    \n",
    "    # Metric: jumlah area piksel yang bernilai 1\n",
    "    labeled_image = lab(gray_image > 0)\n",
    "    # print(type(labeled_image))\n",
    "    props = regionprops(labeled_image)\n",
    "    # print(type(props))\n",
    "    area = props[0].area if props else 0\n",
    "    # print(type(area))\n",
    "    features.append(area)\n",
    "    \n",
    "    # Eccentricity: eksentrisitas region\n",
    "    if props:\n",
    "        eccentricity = props[0].eccentricity\n",
    "    else:\n",
    "        eccentricity = 0\n",
    "    features.append(eccentricity)\n",
    "    \n",
    "    # GLCM (Gray Level Co-occurrence Matrix)\n",
    "    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    features.append(contrast)\n",
    "    features.append(energy)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'OUPUT_DATASET/data latih'\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Load images and extract features\n",
    "X = []\n",
    "y = []\n",
    "label_mapping = {}  # Dictionary untuk memetakan angka ke label\n",
    "feature_extractor = HsvExtractor()\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    # print(idx)\n",
    "    img = cv2.imread(image_file)\n",
    "    image = extract_features(img)\n",
    "    X.append(image)\n",
    "    # Dapatkan label dari nama berkas (misal: 'Ayam Tidak Segar_1.jpg' menjadi 'Ayam Tidak Segar')\n",
    "    label = image_file.split('/')[-1].split('_')[0]\n",
    "    if label not in label_mapping:\n",
    "        label_mapping[label] = idx  # Setiap label memiliki angka unik\n",
    "    y.append(label_mapping[label])\n",
    "\n",
    "# Export dictionary label_mapping\n",
    "with open('label_mapping.json', 'w') as json_file:\n",
    "    json.dump(label_mapping, json_file)\n",
    "\n",
    "X_train = X\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'OUPUT_DATASET/data testing'\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Load images and extract features\n",
    "X = []\n",
    "y = []\n",
    "# label_mapping = {}  # Dictionary untuk memetakan angka ke label\n",
    "# feature_extractor = HsvExtractor()\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    # print(idx)\n",
    "    # crop_object(image_file)\n",
    "    img = cv2.imread(image_file)\n",
    "    image = extract_features(img)\n",
    "    X.append(image)\n",
    "    # Dapatkan label dari nama berkas (misal: 'Ayam Tidak Segar_1.jpg' menjadi 'Ayam Tidak Segar')\n",
    "    label = image_file.split('/')[-1].split('_')[0]\n",
    "    if label not in label_mapping:\n",
    "        label_mapping[label] = idx  # Setiap label memiliki angka unik\n",
    "    y.append(label_mapping[label])\n",
    "\n",
    "# # Export dictionary label_mapping\n",
    "# with open('label_mapping.json', 'w') as json_file:\n",
    "#     json.dump(label_mapping, json_file)\n",
    "\n",
    "X_test = X\n",
    "y_test = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_features = np.array([image for image in X_train])\n",
    "X_test_features = np.array([image for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN classification\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train_features, y_train)\n",
    "\n",
    "# Save KNN model to file\n",
    "pickle.dump(knn, open('KNN.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE: 29.725410005582766\n",
      "Akurasi KNN: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate KNN model\n",
    "knn_preds = knn.predict(X_test)\n",
    "knn_rmse = mean_squared_error(y_test, knn_preds, squared=False)\n",
    "print('KNN RMSE:', knn_rmse)\n",
    "\n",
    "# tampikan akurasinya\n",
    "print('Akurasi KNN:', knn.score(X_test, y_test))\n",
    "\n",
    "# Save KNN model to file\n",
    "with open('KNN.pkl', 'wb') as knn_model_file:\n",
    "    pickle.dump(knn, knn_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi KNN: 55.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "# Fungsi untuk mengekstrak fitur dari gambar\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "\n",
    "    # Mengubah gambar menjadi grayscale\n",
    "    gray_image = rgb2gray(image)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Metric: Jumlah area piksel yang bernilai 1\n",
    "    labeled_image = label(gray_image > 0)\n",
    "    props = regionprops(labeled_image)\n",
    "    area = props[0].area if props else 0\n",
    "    features.append(area)\n",
    "\n",
    "    # Eccentricity: Eksentrisitas region\n",
    "    if props:\n",
    "        eccentricity = props[0].eccentricity\n",
    "    else:\n",
    "        eccentricity = 0\n",
    "    features.append(eccentricity)\n",
    "\n",
    "    # GLCM (Gray Level Co-occurrence Matrix)\n",
    "    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    features.append(contrast)\n",
    "    features.append(energy)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Membaca dataset dari folder Latih dan folder Uji\n",
    "def load_dataset(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_mapping = {}  # Dictionary untuk memetakan angka ke label\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Mengambil label dari nama berkas\n",
    "            label = filename.split(' ')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "            # Membaca dan mengekstrak fitur gambar\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            features = extract_features(image)\n",
    "            images.append(features)\n",
    "\n",
    "            # Menambahkan label ke dalam dictionary jika belum ada\n",
    "            if label not in label_mapping:\n",
    "                label_mapping[label] = idx  # Setiap label memiliki angka unik\n",
    "\n",
    "    return images, labels, label_mapping\n",
    "\n",
    "# Memuat dataset latih dan uji\n",
    "latih_images, latih_labels, label_mapping_latih = load_dataset('OUPUT_DATASET/data latih')\n",
    "uji_images, uji_labels, label_mapping_uji = load_dataset('OUPUT_DATASET/data testing')\n",
    "\n",
    "# Membagi dataset latih menjadi data latih dan data validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(latih_images, latih_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menginisialisasi dan melatih model KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Melakukan prediksi pada data validasi\n",
    "y_pred = knn.predict(X_val)\n",
    "\n",
    "# Menghitung akurasi model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Akurasi KNN: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save KNN model to file\n",
    "with open('KNN.pkl', 'wb') as knn_model_file:\n",
    "    pickle.dump(knn, knn_model_file)\n",
    "\n",
    "# Export label_mapping ke dalam JSON\n",
    "with open('label_mapping.json', 'w') as json_file:\n",
    "    json.dump(label_mapping_uji, json_file)\n",
    "\n",
    "# Melakukan prediksi pada data uji\n",
    "y_uji_pred = knn.predict(uji_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def normalize(data, min_value, max_value):\n",
    "    \"\"\"\n",
    "    Normalizes a float to the range [0, 1].\n",
    "\n",
    "    Args:\n",
    "        data: The float to be normalized.\n",
    "        min_value: The minimum value in the input data.\n",
    "        max_value: The maximum value in the input data.\n",
    "\n",
    "    Returns:\n",
    "        A normalized float.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check for invalid input\n",
    "\n",
    "    if not isinstance(data, float):\n",
    "        raise ValueError(\"data must be a float\")\n",
    "\n",
    "    if min_value >= max_value:\n",
    "        raise ValueError(\"min_value must be less than max_value\")\n",
    "\n",
    "    # Calculate the range of the input data\n",
    "\n",
    "    range_value = max_value - min_value\n",
    "\n",
    "    # Normalize the input data\n",
    "\n",
    "    normalized_data = (data - min_value) / range_value\n",
    "\n",
    "    return normalized_data\n",
    "\n",
    "# Fungsi untuk mengekstrak fitur dari gambar\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "\n",
    "    # Mengubah gambar menjadi grayscale\n",
    "    gray_image = rgb2gray(image)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Metric: Jumlah area piksel yang bernilai 1\n",
    "    labeled_image = label(gray_image > 0)\n",
    "    props = regionprops(labeled_image)\n",
    "    area = props[0].area if props else 0\n",
    "\n",
    "    # Eccentricity: Eksentrisitas region\n",
    "    if props:\n",
    "        eccentricity = props[0].eccentricity\n",
    "    else:\n",
    "        eccentricity = 0\n",
    "\n",
    "    # # Gabungkan Metric dan Eccentricity menjadi satu fitur\n",
    "    # combined_feature = [\n",
    "    #     normalize(area, 86070.0, 3288384.0), \n",
    "    #     normalize(eccentricity, 0.052746550212344645, 0.9687462317467702)]\n",
    "    # features.extend(combined_feature)\n",
    "\n",
    "    # GLCM (Gray Level Co-occurrence Matrix)\n",
    "    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "\n",
    "    # Ekstraksi fitur entropy dan homogenitas\n",
    "    entropy = -np.sum(glcm * np.log(glcm + np.finfo(float).eps))\n",
    "    homogeneity = np.sum(glcm / (1.0 + np.abs(0 - 1)))\n",
    "\n",
    "     # Normalisasi fitur\n",
    "    normalized_area = normalize(area, 86070.0, 3288384.0)\n",
    "    normalized_eccentricity = normalize(eccentricity, 0.052746550212344645, 0.9687462317467702)\n",
    "    normalized_contrast = normalize(contrast, 3.09712535728869, 379.15949047118636)\n",
    "    normalized_energy = normalize(energy, 0.0303806915008107, 0.6785592519223528)\n",
    "    normalized_entropy = normalize(entropy, 0, 7)  # Rentang nilai entropy biasanya [0, 7]\n",
    "    normalized_homogeneity = normalize(homogeneity, 0, 1)  # Rentang nilai homogenitas biasanya [0, 1]\n",
    "\n",
    "    # Gabungkan semua fitur menjadi satu\n",
    "    combined_feature = [\n",
    "        normalized_area, normalized_eccentricity,\n",
    "        normalized_contrast, normalized_energy,\n",
    "        normalized_entropy, normalized_homogeneity\n",
    "    ]\n",
    "\n",
    "    features.extend(combined_feature)\n",
    "    \n",
    "\n",
    "    # features = [i / 255 for i in features]\n",
    "    # print(features)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Membaca dataset dari folder Latih dan folder Uji\n",
    "def load_dataset(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_mapping = {}  # Dictionary untuk memetakan angka ke label\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Mengambil label dari nama berkas\n",
    "            label = filename.split(' ')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "            # Membaca dan mengekstrak fitur gambar\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            features = extract_features(image)\n",
    "            images.append(features)\n",
    "\n",
    "            # Menambahkan label ke dalam dictionary jika belum ada\n",
    "            if label not in label_mapping:\n",
    "                label_mapping[label] = idx  # Setiap label memiliki angka unik\n",
    "\n",
    "    return images, labels, label_mapping\n",
    "\n",
    "# Memuat dataset latih dan uji\n",
    "latih_images, latih_labels, label_mapping_latih = load_dataset('OUPUT_DATASET/Latih')\n",
    "uji_images, uji_labels, label_mapping_uji = load_dataset('OUPUT_DATASET/Uji')\n",
    "\n",
    "# Fungsi untuk melakukan klasifikasi menggunakan KNN dengan fitur yang diberikan\n",
    "def classify_and_evaluate(features, labels, knn_neighbors, name_model):\n",
    "    # Membagi dataset latih menjadi data latih dan data validasi\n",
    "    X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Menginisialisasi dan melatih model KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=knn_neighbors)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Melakukan prediksi pada data validasi\n",
    "    y_pred = knn.predict(X_val)\n",
    "\n",
    "    # Menghitung akurasi model\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    # Save KNN model to file\n",
    "    with open(f'{name_model}.pkl', 'wb') as knn_model_file:\n",
    "        pickle.dump(knn, knn_model_file)\n",
    "\n",
    "    # Export label_mapping ke dalam JSON\n",
    "    with open(f'label_mapping_{name_model}.json', 'w') as json_file:\n",
    "        json.dump(label_mapping_uji, json_file)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def normalize(features):\n",
    "    # Mencari nilai minimum dan maksimum untuk setiap fitur\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "    for feature in features:\n",
    "        min_values.append(min(feature))\n",
    "        max_values.append(max(feature))\n",
    "\n",
    "    # Melakukan normalisasi\n",
    "    for i, feature in enumerate(features):\n",
    "        features[i] = (feature - min_values[i]) / (max_values[i] - min_values[i])\n",
    "\n",
    "    return features\n",
    "\n",
    "# Ekstraksi fitur untuk masing-masing jenis\n",
    "features_sets = {\n",
    "    'Eccentricity Metric': [feat[:2] for feat in latih_images],  # Menggunakan gabungan Eccentricity dan Metric\n",
    "    'GLCM': [feat[2:] for feat in latih_images]\n",
    "}\n",
    "\n",
    "def flatten_list(list_of_lists):\n",
    "    flat_list = []\n",
    "    for sublist in list_of_lists:\n",
    "        flat_list.extend(sublist)\n",
    "\n",
    "    return flat_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GLCM Contrast'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\Users\\herutriana44\\Documents\\joki\\DATASET DAUN HERBAL\\BuildModel\\KlasifikasiDaunHerbal.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m features_sets2 \u001b[39m=\u001b[39m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mEccentricity Metric\u001b[39m\u001b[39m'\u001b[39m: features_sets[\u001b[39m'\u001b[39m\u001b[39mEccentricity Metric\u001b[39m\u001b[39m'\u001b[39m],  \u001b[39m# Menggunakan gabungan Eccentricity dan Metric\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGLCM Contrast\u001b[39m\u001b[39m'\u001b[39m: flatten_list(features_sets[\u001b[39m'\u001b[39;49m\u001b[39mGLCM Contrast\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGLCM Energy\u001b[39m\u001b[39m'\u001b[39m: flatten_list(features_sets[\u001b[39m'\u001b[39m\u001b[39mGLCM Energy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m }\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GLCM Contrast'"
     ]
    }
   ],
   "source": [
    "features_sets2 = {\n",
    "    'Eccentricity Metric': features_sets['Eccentricity Metric'],  # Menggunakan gabungan Eccentricity dan Metric\n",
    "    'GLCM Contrast': flatten_list(features_sets['GLCM Contrast']),\n",
    "    'GLCM Energy': flatten_list(features_sets['GLCM Energy'])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.09712535728869\n",
      "379.15949047118636\n"
     ]
    }
   ],
   "source": [
    "# GLCM Contrast\n",
    "col = 'GLCM Contrast'\n",
    "print(min(features_sets2[col]))\n",
    "print(max(features_sets2[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0303806915008107\n",
      "0.6785592519223528\n"
     ]
    }
   ],
   "source": [
    "# GLCM Contrast\n",
    "col = 'GLCM Energy'\n",
    "print(min(features_sets2[col]))\n",
    "print(max(features_sets2[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[191878.0, 0.8280297669312676]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sets2[col][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat1\n",
      "=> min : 86070.0\n",
      "=> max : 3288384.0\n",
      "feat2\n",
      "=> min : 0.052746550212344645\n",
      "=> max : 0.9687462317467702\n"
     ]
    }
   ],
   "source": [
    "# GLCM Contrast\n",
    "col = 'Eccentricity Metric'\n",
    "feat1 = [feat[0] for feat in features_sets2[col]]\n",
    "feat2 = [feat[1] for feat in features_sets2[col]]\n",
    "print(f\"feat1\\n=> min : {min(feat1)}\\n=> max : {max(feat1)}\")\n",
    "print(f\"feat2\\n=> min : {min(feat2)}\\n=> max : {max(feat2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi KNN dengan fitur Eccentricity Metric: 60.00%\n",
      "Akurasi KNN dengan fitur GLCM: 46.00%\n"
     ]
    }
   ],
   "source": [
    "# Klasifikasi dan evaluasi untuk setiap jenis fitur\n",
    "for feature_name, feature_set in features_sets.items():\n",
    "    accuracy = classify_and_evaluate(feature_set, latih_labels, 3, feature_name)\n",
    "    print(f\"Akurasi KNN dengan fitur {feature_name}: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n  y sizes: 200\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Users\\herutriana44\\Documents\\joki\\DATASET DAUN HERBAL\\BuildModel\\KlasifikasiDaunHerbal.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m \u001b[39m# Melatih model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39m# Mengevaluasi model pada data validasi\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Users/herutriana44/Documents/joki/DATASET%20DAUN%20HERBAL/BuildModel/KlasifikasiDaunHerbal.ipynb#X12sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m val_loss, val_accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n",
      "File \u001b[1;32mc:\\Users\\herutriana44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\herutriana44\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\data_adapter.py:1852\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1845\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1846\u001b[0m         label,\n\u001b[0;32m   1847\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1848\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1849\u001b[0m         ),\n\u001b[0;32m   1850\u001b[0m     )\n\u001b[0;32m   1851\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1852\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n  y sizes: 200\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Fungsi untuk mengekstrak fitur dari gambar\n",
    "def extract_features(image):\n",
    "    # Mengubah gambar menjadi grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize gambar menjadi ukuran 32x32\n",
    "    resized_image = cv2.resize(gray_image, (32, 32))\n",
    "\n",
    "    # Mengembalikan fitur gambar\n",
    "    return resized_image\n",
    "\n",
    "# Membaca dataset dari folder Latih dan folder Uji\n",
    "def load_dataset(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Mengambil label dari nama berkas\n",
    "            label = filename.split(' ')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "            # Membaca dan mengekstrak fitur gambar\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            features = extract_features(image)\n",
    "            images.append(features)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# Memuat dataset latih dan uji\n",
    "latih_images, latih_labels = load_dataset('OUPUT_DATASET/Latih')\n",
    "uji_images, uji_labels = load_dataset('OUPUT_DATASET/Uji')\n",
    "\n",
    "# Mengubah label string menjadi integer\n",
    "le = LabelEncoder()\n",
    "le.fit(latih_labels)\n",
    "latih_labels = le.transform(latih_labels)\n",
    "uji_labels = le.transform(uji_labels)\n",
    "\n",
    "# Mengubah label menjadi one-hot encoding\n",
    "latih_labels = to_categorical(latih_labels)\n",
    "uji_labels = to_categorical(uji_labels)\n",
    "\n",
    "# Membagi dataset latih menjadi data latih dan data validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(latih_images, latih_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Membangun model CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(latih_labels[0]), activation='softmax'))\n",
    "\n",
    "# Kompilasi model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Melatih model\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# Mengevaluasi model pada data validasi\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f'Loss validasi: {val_loss:.4f}, Akurasi validasi: {val_accuracy:.2f}%')\n",
    "\n",
    "# Menyimpan model\n",
    "model.save('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export label_mapping ke dalam JSON\n",
    "with open('label_mapping.json', 'w') as json_file:\n",
    "    json.dump(label_mapping_latih, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_dict(d):\n",
    "    return {v: k for k, v in d.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gambar: Cemara, Prediksi: Ginko, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Sambiloto, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Cemara, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Cemara, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Maja, Label Asli: Cemara\n",
      "Gambar: Emas, Prediksi: Ginko, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Ginko, Prediksi: Ginko, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Emas, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Emas, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Ginko, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Emas, Label Asli: Ginko\n",
      "Gambar: Lemon, Prediksi: Emas, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Pegagan, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Lemon, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Maja, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Maja, Label Asli: Lemon\n",
      "Gambar: Maja, Prediksi: Ginko, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Maja, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Ginko, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Sambiloto, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Sirsak, Label Asli: Maja\n",
      "Gambar: Pegagan, Prediksi: Pegagan, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Lemon, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Ginko, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Ginko, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Ginko, Label Asli: Pegagan\n",
      "Gambar: Sambiloto, Prediksi: Sambiloto, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Pegagan, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Pegagan, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Sambiloto, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Sambiloto, Label Asli: Sambiloto\n",
      "Gambar: Sirsak, Prediksi: Sirsak, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Maja, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Maja, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Sirsak, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Maja, Label Asli: Sirsak\n",
      "Gambar: Stevia, Prediksi: Cemara, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n"
     ]
    }
   ],
   "source": [
    "label_mapping_latih2 = reverse_dict(label_mapping_uji)\n",
    "# Menampilkan hasil prediksi pada data uji\n",
    "for i in range(len(uji_images)):\n",
    "    label = uji_labels[i]\n",
    "    label_index = label_mapping_uji[label]\n",
    "    label_name = label_mapping_latih2[label_index]\n",
    "    print(f\"Gambar: {label}, Prediksi: {y_uji_pred[i]}, Label Asli: {label_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ext = 'dataset\\Latih\\Cemara Kipas 1.jpg'\n",
    "\n",
    "\n",
    "def crop_object(image_ext, output):\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    #img = cv2.imread(\"test.png\")\n",
    "    img = cv2.imread(image_ext)\n",
    "    blurred = cv2.blur(img, (5,5))\n",
    "    canny = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "    ## find the non-zero min-max coords of canny\n",
    "    pts = np.argwhere(canny>0)\n",
    "    y1,x1 = pts.min(axis=0)\n",
    "    y2,x2 = pts.max(axis=0)\n",
    "\n",
    "    ## crop the region\n",
    "    cropped = img[y1:y2, x1:x2]\n",
    "    cv2.imwrite(output, cropped)\n",
    "\n",
    "    # tagged = cv2.rectangle(img.copy(), (x1,y1), (x2,y2), (0,255,0), 3, cv2.LINE_AA)\n",
    "    # cv2.imwrite('hasil_crop.jpg', tagged)\n",
    "    # cv2.imshow(\"tagged\", tagged)\n",
    "    # cv2.waitKey()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Mengimpor model Ultra-Analytix YOLO\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Membaca citra\n",
    "image = cv2.imread(image_ext)\n",
    "\n",
    "# Membuat objek Ultra-Analytix YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Mendeteksi objek pada citra\n",
    "results = model.detect(source=Image.open(image_ext), save=True)\n",
    "\n",
    "# Mendapatkan hasil deteksi\n",
    "for result in results:\n",
    "    class_id, confidence, box = result\n",
    "    class_name = model.class_names[class_id]\n",
    "\n",
    "    # Menggambar kotak dan label pada objek yang terdeteksi\n",
    "    x, y, w, h = box\n",
    "    color = (0, 255, 0)  # Warna hijau\n",
    "    thickness = 2\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), color, thickness)\n",
    "    cv2.putText(image, f'{class_name}: {confidence:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "# Menyimpan citra dengan objek yang terdeteksi\n",
    "cv2.imwrite('hasil_deteksi.jpg', image)\n",
    "\n",
    "# Menampilkan hasil deteksi\n",
    "cv2.imshow('Hasil Deteksi', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dataset/Uji'\n",
    "output_dataset = 'OUPUT_DATASET/'\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Load images and extract features\n",
    "X = []\n",
    "y = []\n",
    "# label_mapping = {}  # Dictionary untuk memetakan angka ke label\n",
    "# feature_extractor = HsvExtractor()\n",
    "for idx, image_file in enumerate(image_files):\n",
    "    # print(idx)\n",
    "    label = image_file.split('/')[-1].split(' ')[0]\n",
    "    crop_object(image_file, f\"{output_dataset}{label} {idx}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi KNN: 55.00%\n",
      "Gambar: Cemara, Prediksi: Ginko, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Sambiloto, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Cemara, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Cemara, Label Asli: Cemara\n",
      "Gambar: Cemara, Prediksi: Maja, Label Asli: Cemara\n",
      "Gambar: Emas, Prediksi: Ginko, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Emas, Prediksi: Emas, Label Asli: Emas\n",
      "Gambar: Ginko, Prediksi: Ginko, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Emas, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Emas, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Ginko, Label Asli: Ginko\n",
      "Gambar: Ginko, Prediksi: Emas, Label Asli: Ginko\n",
      "Gambar: Lemon, Prediksi: Emas, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Pegagan, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Lemon, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Maja, Label Asli: Lemon\n",
      "Gambar: Lemon, Prediksi: Maja, Label Asli: Lemon\n",
      "Gambar: Maja, Prediksi: Ginko, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Maja, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Ginko, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Sambiloto, Label Asli: Maja\n",
      "Gambar: Maja, Prediksi: Sirsak, Label Asli: Maja\n",
      "Gambar: Pegagan, Prediksi: Pegagan, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Lemon, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Ginko, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Ginko, Label Asli: Pegagan\n",
      "Gambar: Pegagan, Prediksi: Ginko, Label Asli: Pegagan\n",
      "Gambar: Sambiloto, Prediksi: Sambiloto, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Pegagan, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Pegagan, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Sambiloto, Label Asli: Sambiloto\n",
      "Gambar: Sambiloto, Prediksi: Sambiloto, Label Asli: Sambiloto\n",
      "Gambar: Sirsak, Prediksi: Sirsak, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Maja, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Maja, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Sirsak, Label Asli: Sirsak\n",
      "Gambar: Sirsak, Prediksi: Maja, Label Asli: Sirsak\n",
      "Gambar: Stevia, Prediksi: Cemara, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Stevia, Prediksi: Stevia, Label Asli: Stevia\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n",
      "Gambar: Zaitun, Prediksi: Zaitun, Label Asli: Zaitun\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.color import rgb2gray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def crop_object(img):\n",
    "    blurred = cv2.blur(img, (5,5))\n",
    "    canny = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "    ## find the non-zero min-max coords of canny\n",
    "    pts = np.argwhere(canny>0)\n",
    "    y1,x1 = pts.min(axis=0)\n",
    "    y2,x2 = pts.max(axis=0)\n",
    "\n",
    "    ## crop the region\n",
    "    cropped = img[y1:y2, x1:x2]\n",
    "    return cropped\n",
    "\n",
    "# Fungsi untuk mengekstrak fitur dari gambar\n",
    "def extract_features(image):\n",
    "    features = []\n",
    "\n",
    "    # Mengubah gambar menjadi grayscale\n",
    "    gray_image = rgb2gray(image)\n",
    "    gray_image = (gray_image * 255).astype(np.uint8)\n",
    "\n",
    "    # Metric: Jumlah area piksel yang bernilai 1\n",
    "    labeled_image = label(gray_image > 0)\n",
    "    props = regionprops(labeled_image)\n",
    "    area = props[0].area if props else 0\n",
    "    features.append(area)\n",
    "\n",
    "    # Eccentricity: Eksentrisitas region\n",
    "    if props:\n",
    "        eccentricity = props[0].eccentricity\n",
    "    else:\n",
    "        eccentricity = 0\n",
    "    features.append(eccentricity)\n",
    "\n",
    "    # GLCM (Gray Level Co-occurrence Matrix)\n",
    "    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    features.append(contrast)\n",
    "    features.append(energy)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Membaca dataset dari folder Latih dan folder Uji\n",
    "def load_dataset(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_mapping = {}  # Dictionary untuk memetakan angka ke label\n",
    "\n",
    "    for idx, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.jpg'):\n",
    "            # Mengambil label dari nama berkas\n",
    "            label = filename.split(' ')[0]\n",
    "            labels.append(label)\n",
    "\n",
    "            # Membaca dan mengekstrak fitur gambar\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            features = extract_features(crop_object(image))\n",
    "            images.append(features)\n",
    "\n",
    "            # Menambahkan label ke dalam dictionary jika belum ada\n",
    "            if label not in label_mapping:\n",
    "                label_mapping[label] = idx  # Setiap label memiliki angka unik\n",
    "\n",
    "    return images, labels, label_mapping\n",
    "\n",
    "# Memuat dataset latih dan uji\n",
    "latih_images, latih_labels, label_mapping_latih = load_dataset('dataset/Latih')\n",
    "uji_images, uji_labels, label_mapping_uji = load_dataset('dataset/Uji')\n",
    "\n",
    "# Membagi dataset latih menjadi data latih dan data validasi\n",
    "X_train, X_val, y_train, y_val = train_test_split(latih_images, latih_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Menginisialisasi dan melatih model KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Melakukan prediksi pada data validasi\n",
    "y_pred = knn.predict(X_val)\n",
    "\n",
    "# Menghitung akurasi model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Akurasi KNN: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save KNN model to file\n",
    "with open('KNN.pkl', 'wb') as knn_model_file:\n",
    "    pickle.dump(knn, knn_model_file)\n",
    "\n",
    "# Export label_mapping ke dalam JSON\n",
    "with open('label_mapping.json', 'w') as json_file:\n",
    "    json.dump(label_mapping_uji, json_file)\n",
    "\n",
    "# Melakukan prediksi pada data uji\n",
    "y_uji_pred = knn.predict(uji_images)\n",
    "\n",
    "# Export label_mapping ke dalam JSON\n",
    "with open('label_mapping.json', 'w') as json_file:\n",
    "    json.dump(label_mapping_latih, json_file)\n",
    "\n",
    "def reverse_dict(d):\n",
    "    return {v: k for k, v in d.items()}\n",
    "\n",
    "label_mapping_latih2 = reverse_dict(label_mapping_uji)\n",
    "# Menampilkan hasil prediksi pada data uji\n",
    "for i in range(len(uji_images)):\n",
    "    label = uji_labels[i]\n",
    "    label_index = label_mapping_uji[label]\n",
    "    label_name = label_mapping_latih2[label_index]\n",
    "    print(f\"Gambar: {label}, Prediksi: {y_uji_pred[i]}, Label Asli: {label_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

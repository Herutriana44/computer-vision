{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'Data/'\n",
    "data_dir_folder = os.listdir(data_dir)\n",
    "\n",
    "ayamsegar = os.listdir(data_dir+data_dir_folder[0])\n",
    "ayamSegar = [f'Ayam Segar_{i}.jpg' for i in range(len(ayamsegar))]\n",
    "for i in range(len(ayamSegar)):\n",
    "    os.rename(data_dir+data_dir_folder[0]+'/'+ayamsegar[i],data_dir+data_dir_folder[0]+'/'+ayamSegar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'Data/'\n",
    "data_dir_folder = os.listdir(data_dir)\n",
    "\n",
    "ayamtidaksegar = os.listdir(data_dir+data_dir_folder[1])\n",
    "ayamtidakSegar = [f'Ayam Tidak Segar_{i}.jpg' for i in range(len(ayamtidaksegar))]\n",
    "for i in range(len(ayamtidaksegar)):\n",
    "    os.rename(data_dir+data_dir_folder[1]+'/'+ayamtidaksegar[i],data_dir+data_dir_folder[1]+'/'+ayamtidakSegar[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 18:32:29.989959: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 18:32:31.045596: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-03-22 18:32:31.045808: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-22 18:32:34.207397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 18:32:34.207558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-22 18:32:34.207574: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m label \u001b[39m=\u001b[39m image_file\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     36\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m datagen\u001b[39m.\u001b[39mflow(img, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_to_dir\u001b[39m=\u001b[39maugmented_dir, save_prefix\u001b[39m=\u001b[39mlabel, save_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mjpg\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     38\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     39\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m \u001b[39m20\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:156\u001b[0m, in \u001b[0;36mIterator.__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 156\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:168\u001b[0m, in \u001b[0;36mIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     index_array \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_generator)\n\u001b[1;32m    166\u001b[0m \u001b[39m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39m# so it can be done in parallel\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:801\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    799\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx[j]\n\u001b[1;32m    800\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mget_random_transform(x\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 801\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_data_generator\u001b[39m.\u001b[39;49mapply_transform(\n\u001b[1;32m    802\u001b[0m     x\u001b[39m.\u001b[39;49mastype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype), params\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    804\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_data_generator\u001b[39m.\u001b[39mstandardize(x)\n\u001b[1;32m    805\u001b[0m batch_x[i] \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:2011\u001b[0m, in \u001b[0;36mImageDataGenerator.apply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m img_col_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_axis \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   2009\u001b[0m img_channel_axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchannel_axis \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 2011\u001b[0m x \u001b[39m=\u001b[39m apply_affine_transform(\n\u001b[1;32m   2012\u001b[0m     x,\n\u001b[1;32m   2013\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtheta\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[1;32m   2014\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[1;32m   2015\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mty\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[1;32m   2016\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mshear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m0\u001b[39;49m),\n\u001b[1;32m   2017\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mzx\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m   2018\u001b[0m     transform_parameters\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mzy\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m   2019\u001b[0m     row_axis\u001b[39m=\u001b[39;49mimg_row_axis,\n\u001b[1;32m   2020\u001b[0m     col_axis\u001b[39m=\u001b[39;49mimg_col_axis,\n\u001b[1;32m   2021\u001b[0m     channel_axis\u001b[39m=\u001b[39;49mimg_channel_axis,\n\u001b[1;32m   2022\u001b[0m     fill_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_mode,\n\u001b[1;32m   2023\u001b[0m     cval\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcval,\n\u001b[1;32m   2024\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation_order,\n\u001b[1;32m   2025\u001b[0m )\n\u001b[1;32m   2027\u001b[0m \u001b[39mif\u001b[39;00m transform_parameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mchannel_shift_intensity\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2028\u001b[0m     x \u001b[39m=\u001b[39m apply_channel_shift(\n\u001b[1;32m   2029\u001b[0m         x,\n\u001b[1;32m   2030\u001b[0m         transform_parameters[\u001b[39m\"\u001b[39m\u001b[39mchannel_shift_intensity\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   2031\u001b[0m         img_channel_axis,\n\u001b[1;32m   2032\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:2609\u001b[0m, in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m   2606\u001b[0m final_affine_matrix \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, :\u001b[39m2\u001b[39m]\n\u001b[1;32m   2607\u001b[0m final_offset \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[0;32m-> 2609\u001b[0m channel_images \u001b[39m=\u001b[39m [\n\u001b[1;32m   2610\u001b[0m     ndimage\u001b[39m.\u001b[39minterpolation\u001b[39m.\u001b[39maffine_transform(\n\u001b[1;32m   2611\u001b[0m         x_channel,\n\u001b[1;32m   2612\u001b[0m         final_affine_matrix,\n\u001b[1;32m   2613\u001b[0m         final_offset,\n\u001b[1;32m   2614\u001b[0m         order\u001b[39m=\u001b[39morder,\n\u001b[1;32m   2615\u001b[0m         mode\u001b[39m=\u001b[39mfill_mode,\n\u001b[1;32m   2616\u001b[0m         cval\u001b[39m=\u001b[39mcval,\n\u001b[1;32m   2617\u001b[0m     )\n\u001b[1;32m   2618\u001b[0m     \u001b[39mfor\u001b[39;00m x_channel \u001b[39min\u001b[39;00m x\n\u001b[1;32m   2619\u001b[0m ]\n\u001b[1;32m   2620\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(channel_images, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   2621\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrollaxis(x, \u001b[39m0\u001b[39m, channel_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/keras/preprocessing/image.py:2610\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2606\u001b[0m final_affine_matrix \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, :\u001b[39m2\u001b[39m]\n\u001b[1;32m   2607\u001b[0m final_offset \u001b[39m=\u001b[39m transform_matrix[:\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m]\n\u001b[1;32m   2609\u001b[0m channel_images \u001b[39m=\u001b[39m [\n\u001b[0;32m-> 2610\u001b[0m     ndimage\u001b[39m.\u001b[39;49minterpolation\u001b[39m.\u001b[39;49maffine_transform(\n\u001b[1;32m   2611\u001b[0m         x_channel,\n\u001b[1;32m   2612\u001b[0m         final_affine_matrix,\n\u001b[1;32m   2613\u001b[0m         final_offset,\n\u001b[1;32m   2614\u001b[0m         order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   2615\u001b[0m         mode\u001b[39m=\u001b[39;49mfill_mode,\n\u001b[1;32m   2616\u001b[0m         cval\u001b[39m=\u001b[39;49mcval,\n\u001b[1;32m   2617\u001b[0m     )\n\u001b[1;32m   2618\u001b[0m     \u001b[39mfor\u001b[39;00m x_channel \u001b[39min\u001b[39;00m x\n\u001b[1;32m   2619\u001b[0m ]\n\u001b[1;32m   2620\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(channel_images, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   2621\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrollaxis(x, \u001b[39m0\u001b[39m, channel_axis \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/scipy/ndimage/_interpolation.py:611\u001b[0m, in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    608\u001b[0m     _nd_image\u001b[39m.\u001b[39mzoom_shift(filtered, matrix, offset\u001b[39m/\u001b[39mmatrix, output, order,\n\u001b[1;32m    609\u001b[0m                          mode, cval, npad, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    610\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     _nd_image\u001b[39m.\u001b[39;49mgeometric_transform(filtered, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, matrix, offset,\n\u001b[1;32m    612\u001b[0m                                   output, order, mode, cval, npad, \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    613\u001b[0m                                   \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    614\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "# List all image files in the dataset directory\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# buat variasi gambar dengan flip rotate dan zoom\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# buat objek ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# buat direktori untuk menyimpan gambar yang telah di augmentasi\n",
    "augmented_dir = 'dataset'\n",
    "\n",
    "# simpan gambar yang telah di augmentasi dengan nama file sesuai label\n",
    "for image_file in image_files:\n",
    "    # baca gambar\n",
    "    img = plt.imread(image_file)\n",
    "    # ubah dimensi gambar menjadi (1, x, y, channel)\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    # buat nama file baru\n",
    "    label = image_file.split('/')[-1].split('.')[0]\n",
    "    i = 0\n",
    "    for batch in datagen.flow(img, batch_size=1, save_to_dir=augmented_dir, save_prefix=label, save_format='jpg'):\n",
    "        i += 1\n",
    "        if i > 20:\n",
    "            break\n",
    "\n",
    "# Path: BuildModel/latihModel.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

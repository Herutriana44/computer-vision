{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dataset/'\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berikut adalah kodingan untuk klasifikasi menggunakan algoritma KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN RMSE: 0.0\n",
      "Akurasi KNN: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "# Path to the dataset directory\n",
    "data_dir = dataset\n",
    "\n",
    "# List all image files in the dataset directory\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Load images and extract features\n",
    "X = []\n",
    "y = []\n",
    "for image_file in image_files:\n",
    "    img = cv2.imread(image_file)\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    hsv_hist = cv2.calcHist([hsv_img], [0, 1, 2], None, [8, 2, 2], [0, 180, 0, 256, 0, 256])\n",
    "    hsv_hist = cv2.normalize(hsv_hist, hsv_hist).flatten()\n",
    "    X.append(hsv_hist)\n",
    "    label = image_file.split('/')[-1].split('_')[0]\n",
    "    # ubah label dari `mata ikan gak segar` menjadi 0 dan` mata ikan segar` menjadi 1\n",
    "    # print(label)\n",
    "    if label == 'tidak segar':\n",
    "        y.append(0)\n",
    "    if label == 'segar':\n",
    "        y.append(1)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# KNN classification\n",
    "knn = KNeighborsClassifier(n_neighbors=50)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Save KNN model to file\n",
    "pickle.dump(knn, open('KNN.pkl', 'wb'))\n",
    "\n",
    "#knn.save('KNN.h5')\n",
    "\n",
    "# Evaluate KNN model\n",
    "knn_preds = knn.predict(X_test)\n",
    "knn_rmse = mean_squared_error(y_test, knn_preds, squared=False)\n",
    "print('KNN RMSE:', knn_rmse)\n",
    "\n",
    "# tampikan akurasinya\n",
    "print('Akurasi KNN:', knn.score(X_test, y_test))\n",
    "\n",
    "joblib.dump(knn, 'knn_model.pkl')\n",
    "with open('knn_model.json', 'w') as f:\n",
    "    f.write(json.dumps(joblib.load('knn_model.pkl').get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berikut adalah kodingan untuk klasifikasi menggunakan algoritma CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "dataset = 'dataset/'\n",
    "import os\n",
    "\n",
    "# Path to the dataset directory\n",
    "data_dir = dataset\n",
    "\n",
    "# List all image files in the dataset directory\n",
    "image_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Load images and extract features\n",
    "X = []\n",
    "y = []\n",
    "for image_file in image_files:\n",
    "    img = cv2.imread(image_file)\n",
    "    #hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #hsv_hist = cv2.calcHist([hsv_img], [0, 1, 2], None, [8, 2, 2], [0, 180, 0, 256, 0, 256])\n",
    "    #hsv_hist = cv2.normalize(hsv_hist, hsv_hist).flatten()\n",
    "    X.append(list(img))\n",
    "    label = image_file.split('/')[-1].split('_')[0]\n",
    "    y.append(label)\n",
    "\n",
    "# Convert data to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# ubah label dari `mata ikan gak segar` menjadi 0 dan` mata ikan segar` menjadi 1\n",
    "y[y == 'tidak segar'] = 0\n",
    "y[y == 'segar'] = 1\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid',dtype='float32'))\n",
    "\n",
    "# Compile the CNN model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "unique_labels = np.unique(y_train)\n",
    "print(unique_labels)\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "y_train = np.array([label_map[label] for label in y_train])\n",
    "\n",
    "unique_labels = np.unique(y_test)\n",
    "label_map = {label: i for i, label in enumerate(unique_labels)}\n",
    "y_test = np.array([label_map[label] for label in y_test])\n",
    "\n",
    "# Train the CNN model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "# Save the CNN model to file\n",
    "model.save('CNN.h5')\n",
    "\n",
    "# Evaluate the CNN model\n",
    "cnn_preds = model.predict(X_test)\n",
    "cnn_preds = np.round(cnn_preds).astype(int).flatten()\n",
    "cnn_rmse = mean_squared_error(y_test, cnn_preds, squared=False)\n",
    "print('CNN RMSE:', cnn_rmse)\n",
    "\n",
    "# Save KNN model to file\n",
    "pickle.dump(model, open('CNN.pkl', 'wb'))\n",
    "# Export model to JSON file\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......mean_metric_wrapper\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-04-19 22:07:40        35392\n",
      "config.json                                    2023-04-19 22:07:40         2093\n",
      "metadata.json                                  2023-04-19 22:07:40           64\n"
     ]
    }
   ],
   "source": [
    "# save model ke pickle\n",
    "import pickle\n",
    "pickle.dump(model, open('CNN.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
